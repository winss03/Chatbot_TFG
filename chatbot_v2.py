from langchain_cohere import ChatCohere
from langchain_cohere import CohereEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
import mysql.connector
import os
import logging
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuraci√≥n de la base de datos usando variables de entorno
DB_CONFIG = {
    'host': os.getenv('DB_HOST'),
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASSWORD'),
    'database': os.getenv('DB_NAME'),
    'port': int(os.getenv('DB_PORT', '3306'))
}

def cargar_datos():
    """Carga y procesa datos de la tabla mensajes"""
    try:
        logger.info("üìö Conectando a la base de datos MySQL...")
        logger.debug(f"DB_CONFIG: {DB_CONFIG}")
        conn = mysql.connector.connect(**DB_CONFIG)
        logger.info("‚úÖ Conexi√≥n exitosa a MySQL")
        cursor = conn.cursor(dictionary=True)

        # Consulta principal
        query = """
        SELECT 
            id,
            device_id,
            sat,
            mov_state,
            voltaje/1000.0 as voltaje_v,
            volt_bateria/1000.0 as bateria_v,
            temperatura,
            fecha_recepcion,
            lat, lng, alt
        FROM mensajes
        ORDER BY fecha_recepcion DESC
        """
        
        cursor.execute(query)
        registros = cursor.fetchall()
        
        # Convertir a objetos Document directamente
        documents = []
        
        # Procesar por dispositivo
        dispositivos = {}
        for reg in registros:
            if reg['device_id'] not in dispositivos:
                dispositivos[reg['device_id']] = []
            dispositivos[reg['device_id']].append(reg)

        # Crear documentos por dispositivo
        for device_id, regs in dispositivos.items():
            ultimo_reg = regs[0]  # El m√°s reciente
            resumen = f"""üì± Dispositivo {device_id}:
                Estado actual:
                ‚Ä¢ Ubicaci√≥n: {ultimo_reg['lat']}, {ultimo_reg['lng']}
                ‚Ä¢ Altitud: {ultimo_reg['alt']} metros
                ‚Ä¢ Movimiento: {'En movimiento' if ultimo_reg['mov_state'] == 1 else 'Detenido'}
                ‚Ä¢ Sat√©lites: {ultimo_reg['sat']}
                ‚Ä¢ Voltaje: {ultimo_reg['voltaje_v']:.2f}V
                ‚Ä¢ Bater√≠a: {ultimo_reg['bateria_v']:.2f}V
                ‚Ä¢ Temperatura: {ultimo_reg['temperatura']}¬∞C
                ‚Ä¢ √öltima actualizaci√≥n: {ultimo_reg['fecha_recepcion']}"""

            # Crear objeto Document directamente
            from langchain.schema import Document
            doc = Document(
                page_content=resumen,
                metadata={
                    "tipo": "estado_actual",
                    "device_id": device_id,
                    "timestamp": str(ultimo_reg['fecha_recepcion'])
                }
            )
            documents.append(doc)

        logger.info(f"‚úÖ Procesados {len(documents)} documentos de {len(dispositivos)} dispositivos")
        return documents

    except Exception as e:
        logger.error(f"‚ùå Error: {str(e)}")
        logger.debug("Error detallado:", exc_info=True)
        return None
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals() and conn.is_connected():
            conn.close()

def configurar_chatbot(documents):
    """Configura el chatbot con los documentos procesados"""
    try:
        logger.info(f"üîÑ Configurando chatbot con {len(documents)} documentos")
        
        # 1. Crear embeddings
        embeddings = CohereEmbeddings(
            cohere_api_key=os.getenv("COHERE_API_KEY"),
            model="embed-multilingual-v3.0"
        )
        
        # 2. Crear base de datos vectorial directamente con los documentos
        vectorstore = FAISS.from_documents(documents, embeddings)
        
        # 3. Configurar memoria
        memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            return_messages=True,
            k=15
        )
        
        # 4. Crear el modelo con configuraci√≥n en espa√±ol
        llm = ChatCohere(
            temperature=0.7,
            model="command-r",
            max_tokens=20,
            prompt_prefix="""Eres un asistente especializado en interpretar informaci√≥n de bases de datos. 
                Eres un asistente amable y conciso que responde siempre en espa√±ol con frases cortas y claras."""
        )
        
        # 5. Crear el prompt template
        prompt = PromptTemplate(
            template="""Eres un asistente especializado en analizar bases de datos de dispositivos IoT.
            Cada fila de la base representa un mensaje enviado por un dispositivo, incluyendo datos como ubicaci√≥n, voltaje, bater√≠a, temperatura, fecha, estado de movimiento y m√°s.

            üîπ Tu tarea es responder SIEMPRE en espa√±ol de forma:
            - Muy breve (1 a 3 l√≠neas)
            - Clara, √∫til y amable
            - Directa y precisa, enfoc√°ndote solo en lo que se pregunta
            - Sin repetir la pregunta ni incluir explicaciones innecesarias

            üî∏ Instrucciones espec√≠ficas:
            - Si preguntan "dame informaci√≥n del dispositivo X" ‚Üí Resume el estado actual incluyendo:
                ‚Ä¢ Sat√©lites conectados (sat)
                ‚Ä¢ Estado de movimiento (mov_state: 0 = Detenido, 1 = En movimiento)
                ‚Ä¢ Voltaje del sistema (voltaje_v)
                ‚Ä¢ Voltaje de bater√≠a (bateria_v)
                ‚Ä¢ Temperatura en ¬∞C
                ‚Ä¢ Fecha y hora del √∫ltimo mensaje (fecha_recepcion)
                ‚Ä¢ Ubicaci√≥n: latitud, longitud, altitud, y ciudad/pueblo cercano si se puede

            - Si preguntan "¬ø Qu√© o Cu√°ntos dispositivos hay?" ‚Üí Solo responde con los device_id separados por comas.

            - Si preguntan "Ubicaci√≥n del dispositivo X" ‚Üí Da el device_id con latitud, longitud y una referencia aproximada a la ciudad o pueblo m√°s cercano.

            - Si preguntan "¬øEst√° en movimiento?" ‚Üí Responde solo ‚ÄúS√≠‚Äù o ‚ÄúNo‚Äù, incluyendo el ID si es relevante.

            - Si preguntan "¬øCu√°ndo fue el √∫ltimo mensaje?" ‚Üí Da solo la fecha y hora exacta.

            - Si preguntan "Voltaje o bater√≠a del dispositivo X" ‚Üí Responde solo con el device_id y el valor en voltios con unidad.

            - Si preguntan "¬øQu√© temperatura tiene el dispositivo?" ‚Üí Responde con el device_id, n√∫mero y ¬∞C.

            ‚ùó Nunca expliques tu estilo de respuesta ni menciones que est√°s siguiendo instrucciones.

            Contexto actual: {context}
            Pregunta: {question}

            Responde:
            """,
                input_variables=["context", "question"]
            )

        
        # 6. Crear la cadena de conversaci√≥n
        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=vectorstore.as_retriever(search_kwargs={"k": 10}),
            memory=memory,
            combine_docs_chain_kwargs={"prompt": prompt},
            verbose=False # Desactivamos verbose para evitar logs excesivos
        )
        
        logger.info("‚úÖ Chatbot configurado correctamente")
        return qa_chain
        
    except Exception as e:
        logger.error(f"‚ùå Error al configurar el chatbot: {e}")
        logger.debug("Error detallado:", exc_info=True)
        return None

def chatbot():
    """Funci√≥n principal del chatbot interactivo"""
    # Cargar datos de la base de datos
    chunks = cargar_datos()  # Cambiamos cargar_documento() por cargar_datos()
    if not chunks:
        logger.error("‚ùå No se pudieron cargar los datos.")
        return
        
    # Configurar el chatbot
    qa_chain = configurar_chatbot(chunks)
    if not qa_chain:
        logger.error("‚ùå No se pudo configurar el chatbot.")
        return
    
    # Iniciar conversaci√≥n
    logger.info("\n ü§ñ Chatbot listo. Escribe tu consulta o 'salir' para finalizar la conversaci√≥n.")
   
    
    while True:
        pregunta = input("\nüë§ Tu consulta: ").strip()
        
        if not pregunta:
            logger.info("‚ùå Por favor, ingresa una pregunta v√°lida.")
            continue
            
        if pregunta.lower() == 'salir':
            logger.info("üëã ¬°Gracias por usar el chatbot! Hasta pronto.")
            break
            
        try:
            
            result = qa_chain.invoke({"question": pregunta})
            respuesta = result['answer']
            
            # Mostrar respuesta
            print("\nü§ñ Respuesta:")
            print(respuesta)
            
        except Exception as e:
            logger.error(f"‚ùå Error al procesar la pregunta: {str(e)}")
            logger.debug("Error detallado:", exc_info=True)

if __name__ == "__main__":
    chatbot()

### C√≥digo para la API REST ###
chatbot_chain = None  # Variable global para mantener la instancia

def inicializar_chatbot():
    global chatbot_chain
    chunks = cargar_datos()
    if not chunks:
        raise Exception("No se pudieron cargar los datos.")
    
    chatbot_chain = configurar_chatbot(chunks)
    if not chatbot_chain:
        raise Exception("No se pudo configurar el chatbot.")
    
    return True

def responder_pregunta(pregunta):
    if not chatbot_chain:
        raise Exception("Chatbot no inicializado.")
    
    result = chatbot_chain.invoke({"question": pregunta})
    return result['answer']
